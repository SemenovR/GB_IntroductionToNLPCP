{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовая работа \"Введение в обработку естественного языка\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Обучение чат-бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import annoy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "from functools import lru_cache\n",
    "from gensim.models import FastText\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к дата-сетам\n",
    "PATH_BASE = 'D:\\\\GB_DB\\\\'\n",
    "# Путь к моделям\n",
    "PATH_MODEL = 'D:\\\\GB_DB\\\\models\\\\'\n",
    "# Размер эмбеддинга\n",
    "SIZE_EMB = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Часть 1.1. Обучение разговорной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяем ответы в отдельный файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = None\n",
    "written = False\n",
    "\n",
    "with open(f'{PATH_BASE}prepared_answers.txt', \"w\", encoding=\"utf8\") as fout:\n",
    "    with open(f'{PATH_BASE}Otvety.txt', \"r\", encoding=\"utf8\") as fin:\n",
    "        for line in tqdm_notebook(fin):\n",
    "            if line.startswith(\"---\"):\n",
    "                written = False\n",
    "                continue\n",
    "            if not written and question is not None:\n",
    "                fout.write(question.replace(\"\\t\", \" \").strip() + \"\\t\" + line.replace(\"\\t\", \" \"))\n",
    "                written = True\n",
    "                question = None\n",
    "                continue\n",
    "            if not written:\n",
    "                question = line.strip()\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции подготовки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def parse_morpher(text):\n",
    "    return morpher.parse(text)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [parse_morpher(re.sub(r'\\<[^>]*\\>', '', i).lower()) for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c4af48e7fd40a8b2846dd0c6bad3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 24min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences = []\n",
    "\n",
    "with open(f'{PATH_BASE}Otvety.txt', \"r\", encoding=\"utf8\") as fin:\n",
    "    for line in tqdm_notebook(fin):\n",
    "        spls = preprocess_txt(line)\n",
    "        sentences.append(spls)\n",
    "        \n",
    "sentences = [i for i in sentences if len(i) > 2]\n",
    "\n",
    "with open(f'{PATH_MODEL}sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(sentences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}sentences.pkl', 'rb') as f:\n",
    "    sentences = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4849714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция-пустышка, для возможности передать в TfidfVectorizer список уже готовых токенов, а не текст\n",
    "def simple_tokenizer(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_v = TfidfVectorizer(tokenizer=simple_tokenizer, lowercase=False, min_df=2)\n",
    "tfidf_v.fit_transform(sentences)\n",
    "\n",
    "idfs = {v[0]: v[1] for v in zip(tfidf_v.vocabulary_, tfidf_v.idf_)}\n",
    "midf = np.mean(tfidf_v.idf_)\n",
    "\n",
    "with open(f'{PATH_MODEL}idfs.pkl', 'wb') as f:\n",
    "    pickle.dump(idfs, f)\n",
    "with open(f'{PATH_MODEL}midf.pkl', 'wb') as f:\n",
    "    pickle.dump(midf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}idfs.pkl', 'rb') as f:\n",
    "    idfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}midf.pkl', 'rb') as f:\n",
    "    midf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelFT = FastText(sentences=sentences, size=SIZE_EMB, min_count=2, window=5, workers=8, seed=34)\n",
    "modelFT.save(f'{PATH_MODEL}modelFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFT = FastText.load(f'{PATH_MODEL}modelFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем ответы в модель приближенного поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4083f464a75f46fa96324eca5626ba6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_index = annoy.AnnoyIndex(SIZE_EMB, 'angular')\n",
    "index_map = {}\n",
    "counter = 0\n",
    "\n",
    "with open(f'{PATH_BASE}prepared_answers.txt', \"r\", encoding=\"utf8\") as f:\n",
    "    for line in tqdm_notebook(f):\n",
    "        n_ft = 0\n",
    "        spls = line.split(\"\\t\")\n",
    "        index_map[counter] = re.sub(r'\\<[^>]*\\>', '', spls[1]) # Удалим html-тэги\n",
    "        question = preprocess_txt(spls[0])\n",
    "        vector_ft = np.zeros(SIZE_EMB)\n",
    "        \n",
    "        for word in question:\n",
    "            if word in modelFT:\n",
    "                vector_ft += modelFT[word]\n",
    "                n_ft += idfs.get(word, midf)\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index.add_item(counter, vector_ft)\n",
    "        counter += 1\n",
    "        \n",
    "ft_index.build(50)\n",
    "ft_index.save(f'{PATH_MODEL}ft_index')\n",
    "\n",
    "with open(f'{PATH_MODEL}index_map.pkl', 'wb') as f:\n",
    "    pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_index = annoy.AnnoyIndex(SIZE_EMB, 'angular')\n",
    "ft_index.load(f'{PATH_MODEL}ft_index') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}index_map.pkl', 'rb') as f:\n",
    "    index_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Часть 1.2. Обучение продуктовой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.25 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title                                       descrirption  \\\n",
       "0  Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n",
       "1          Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2              Брюки  Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "\n",
       "                 product_id  category_id subcategory_id  \\\n",
       "0  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1  5667531b2b7f8d127d838c34          9.0            902   \n",
       "2  59534826aaab284cba337e06          9.0            906   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "\n",
       "                                         image_links  \\\n",
       "0  http://cache3.youla.io/files/images/360_360/58...   \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...   \n",
       "2  http://cache3.youla.io/files/images/360_360/59...   \n",
       "\n",
       "                                                text  \n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  \n",
       "2  [брюки, размер, 4042, брюки, новый, знать, мер...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "shop_data = pd.read_csv(f'{PATH_BASE}ProductsDataset.csv')\n",
    "\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in idxs]\n",
    "positive_texts = [\" \".join(val) for val in shop_data['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, stratify=labels, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "with open(f'{PATH_MODEL}vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "with open(f'{PATH_MODEL}vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_vec, y_train)\n",
    "\n",
    "with open(f'{PATH_MODEL}lr.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "with open(f'{PATH_MODEL}lr.pkl', 'rb') as f:\n",
    "    lr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9787460148777896"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_p = TfidfVectorizer(lowercase=False, min_df=2)\n",
    "tfidf_p.fit(X_train)\n",
    "\n",
    "idfs_p = {v[0]: v[1] for v in zip(tfidf_p.vocabulary_, tfidf_p.idf_)}\n",
    "midf_p = np.mean(tfidf_p.idf_)\n",
    "\n",
    "with open(f'{PATH_MODEL}idfs_p.pkl', 'wb') as f:\n",
    "    pickle.dump(idfs_p, f)\n",
    "with open(f'{PATH_MODEL}midf_p.pkl', 'wb') as f:\n",
    "    pickle.dump(midf_p, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}idfs_p.pkl', 'rb') as f:\n",
    "    idfs_p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}midf_p.pkl', 'rb') as f:\n",
    "    midf_p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b48d63528ea42b18fcaf4603844dc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35548.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_index_shop = annoy.AnnoyIndex(SIZE_EMB, 'angular')\n",
    "index_map_shop = {}\n",
    "counter = 0\n",
    "\n",
    "for i in tqdm_notebook(range(len(shop_data))):\n",
    "    n_ft = 0\n",
    "    index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "    vector_ft = np.zeros(SIZE_EMB)\n",
    "    for word in shop_data.loc[i, \"text\"]:\n",
    "        if word in modelFT:\n",
    "            vector_ft += modelFT[word]\n",
    "            n_ft += idfs_p.get(word, midf_p)\n",
    "    if n_ft > 0:\n",
    "        vector_ft = vector_ft / n_ft\n",
    "    ft_index_shop.add_item(counter, vector_ft)\n",
    "    counter += 1\n",
    "\n",
    "ft_index_shop.build(50)\n",
    "ft_index_shop.save(f'{PATH_MODEL}ft_index_shop')\n",
    "\n",
    "with open(f'{PATH_MODEL}index_map_shop.pkl', 'wb') as f:\n",
    "    pickle.dump(index_map_shop, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_index_shop = annoy.AnnoyIndex(SIZE_EMB, 'angular')\n",
    "ft_index_shop.load(f'{PATH_MODEL}ft_index_shop') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{PATH_MODEL}index_map_shop.pkl', 'rb') as f:\n",
    "    index_map_shop = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на вторую часть проекта - сам чат-бот: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
